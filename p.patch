--- a/src/weavelens/bot/tg_bot.py
+++ b/src/weavelens/bot/tg_bot.py
@@
-from aiogram import types
+from aiogram import types
+from io import BytesIO

+TELEGRAM_MAX_CHARS = 4096
+# оставим запас под служебный хвост/разметку
+TELEGRAM_SAFE_CHARS = 3800
+TO_FILE_THRESHOLD = TELEGRAM_SAFE_CHARS * 5  # если сильно длинно — шлем файлом
+
+async def reply_long(m: types.Message, text: str, footer: str = ""):
+    full_text = text + (footer or "")
+    # если очень много — отправляем как файл
+    if len(full_text) > TO_FILE_THRESHOLD:
+        buf = BytesIO(full_text.encode("utf-8"))
+        buf.name = "search.txt"
+        # у разных версий aiogram разные классы InputFile; самый совместимый способ:
+        await m.reply_document(document=buf, caption="Результаты поиска (см. вложение)")
+        return
+    # иначе — порциями
+    if len(full_text) <= TELEGRAM_MAX_CHARS:
+        await m.reply(full_text)
+        return
+    chunks = [full_text[i:i+TELEGRAM_SAFE_CHARS] for i in range(0, len(full_text), TELEGRAM_SAFE_CHARS)]
+    total = len(chunks)
+    for i, chunk in enumerate(chunks, 1):
+        tail = f"\n\n[{i}/{total}]"
+        await m.reply(chunk + tail)
+    return

@@ async def cmd_search(m: types.Message):
-    text = format_search_response(res)  # как у тебя сейчас
-    await m.reply(text + f"\n\n(API: {used_base})")
+    text = format_search_response(res)  # как у тебя сейчас
+    await reply_long(m, text, footer=f"\n\n(API: {used_base})")
