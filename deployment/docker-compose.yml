services:
  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:latest
    restart: unless-stopped
    ports:
      - "8080:8080"      # REST
      - "50051:50051"    # gRPC
    environment:
      CLUSTER_HOSTNAME: "node1"
      DEFAULT_VECTORIZER_MODULE: "none"
      QUERY_DEFAULTS_LIMIT: "25"
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: "true"
      PERSISTENCE_DATA_PATH: "/var/lib/weaviate"
      ENABLE_MODULES: "bm25"
      DISABLE_TELEMETRY: "true"
    volumes:
      - ../data/weaviate:/var/lib/weaviate
    healthcheck:
      # У weaviate образа обычно есть wget
      test: ["CMD", "wget", "-qO-", "http://localhost:8080/v1/.well-known/ready"]
      interval: 5s
      timeout: 3s
      retries: 40
    profiles: ["server"]

  # ------------ Ollama (CPU) ------------
  ollama:
    image: ollama/ollama:latest
    container_name: deployment-ollama-1
    ports:
      - "11434:11434"
    volumes:
      - ../models:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_NUM_GPU_LAYERS=${OLLAMA_NUM_GPU_LAYERS:-0}
    restart: unless-stopped
    profiles: ["cpu"]

  # ------------ Ollama (GPU/NVIDIA) ------------
  ollama-gpu:
    image: ollama/ollama:latest   # для AMD можно заменить на ollama/ollama:rocm
    container_name: deployment-ollama-1
    ports:
      - "11434:11434"
    volumes:
      - ../models:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_NUM_GPU_LAYERS=${OLLAMA_NUM_GPU_LAYERS:-999}
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    gpus: all
    restart: unless-stopped
    profiles: ["gpu"]
    networks:
      default:
        aliases: [ollama]

  # ------------ API (режим server, с Weaviate) ------------
  api:
    build:
      context: ..
      dockerfile: Dockerfile.api
    env_file:
      - ../.env
    environment:
      # в кластере обращаемся к контейнеру ollama по container_name,
      # который одинаков в обоих профилях (cpu/gpu)
      - OLLAMA_HOST=deployment-ollama-1
      - WEAVIATE_HOST=weaviate
      - WEAVELENS_PROFILE=server
    volumes:
      - ../data:/app/data
      - ../models:/app/models
    ports:
      - "8000:8000"
    depends_on:
      weaviate:
        condition: service_healthy
    healthcheck:
      # используем python, чтобы не тащить curl/wget в образ API
      test:
        [
          "CMD-SHELL",
          "python -c \"import urllib.request,sys; sys.exit(0) if urllib.request.urlopen('http://localhost:8000/api/ready', timeout=2).status==200 else sys.exit(1)\""
        ]
      interval: 5s
      timeout: 3s
      retries: 60
      start_period: 15s
    restart: unless-stopped
    profiles: ["server"]

  # ------------ API (режим embedded, без Weaviate) ------------
  api-embedded:
    build:
      context: ..
      dockerfile: Dockerfile.api
    env_file:
      - ../.env
    environment:
      - OLLAMA_HOST=deployment-ollama-1
      - WEAVELENS_PROFILE=embedded
    volumes:
      - ../data:/app/data
      - ../models:/app/models
    ports:
      - "8000:8000"
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "python -c \"import urllib.request,sys; sys.exit(0) if urllib.request.urlopen('http://localhost:8000/api/ready', timeout=2).status==200 else sys.exit(1)\""
        ]
      interval: 5s
      timeout: 3s
      retries: 60
      start_period: 15s
    restart: unless-stopped
    profiles: ["embedded"]

  # ------------ Bot (для server-режима) ------------
  bot:
    build:
      context: ..
      dockerfile: Dockerfile.bot
    env_file:
      - ../.env
    environment:
      - BOT_API_URL=http://api:8000/api
    volumes:
      - ../data:/app/data
    depends_on:
      api:
        condition: service_healthy
    restart: unless-stopped
    profiles: ["server"]

  # ------------ Bot (для embedded-режима) ------------
  bot-embedded:
    build:
      context: ..
      dockerfile: Dockerfile.bot
    env_file:
      - ../.env
    environment:
      - BOT_API_URL=http://api-embedded:8000/api
    volumes:
      - ../data:/app/data
    depends_on:
      api-embedded:
        condition: service_healthy
    restart: unless-stopped
    profiles: ["embedded"]
